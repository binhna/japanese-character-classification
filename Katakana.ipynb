{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Katakana.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bst7lBn3FQB-",
        "colab_type": "code",
        "outputId": "f64cb7cc-ca1a-48df-945b-96e562d85ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K128JWNRFSnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -qq drive/My\\ Drive/Citynow/Katakana.zip -d ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRuQmxJFFcHw",
        "colab_type": "code",
        "outputId": "4c71f86b-37f7-4454-df00-6d1bfac70dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os, sys\n",
        "from os import walk, listdir\n",
        "from os.path import isfile, join\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from scipy import ndimage\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "import scipy.misc\n",
        "from keras import backend as K\n",
        "from keras import initializers\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdhfglX3Fec8",
        "colab_type": "code",
        "outputId": "08ed3406-55db-4774-af2b-f3c6a0489262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# number of images to feed into the NN for every batch\n",
        "batch_size = 16\n",
        "pic_size = 64\n",
        "\n",
        "datagen = ImageDataGenerator(validation_split=0.2)\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\"Katakana\",\n",
        "                                                    target_size=(pic_size,pic_size),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True,\n",
        "                                                    subset='training')\n",
        "\n",
        "test_generator = datagen.flow_from_directory(\"Katakana\",\n",
        "                                                    target_size=(pic_size,pic_size),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=False,\n",
        "                                                    subset='validation')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 57577 images belonging to 48 classes.\n",
            "Found 14382 images belonging to 48 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWV_FTB8FkVC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_classes = len(list(set(train_generator.classes)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuEnAYKNFmcz",
        "colab_type": "code",
        "outputId": "037eae67-e33e-4930-a6e9-698ff87d9269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "def m12():\n",
        "    model.add(Conv2D(64, (3, 3), input_shape=(64, 64, 1), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(512, (3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(4096))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    \n",
        "    model.add(Dense(nb_classes))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "m12()\n",
        "\n",
        "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False)\n",
        "model.summary()\n",
        "# sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0717 08:41:11.247383 139942940280704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0717 08:41:11.283663 139942940280704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0717 08:41:11.290635 139942940280704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0717 08:41:11.332389 139942940280704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0717 08:41:11.333358 139942940280704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0717 08:41:14.145409 139942940280704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0717 08:41:14.308260 139942940280704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0717 08:41:14.317857 139942940280704 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0717 08:41:15.207285 139942940280704 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 64, 64, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 64, 64, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 32, 32, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 16, 16, 256)       590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 16, 16, 256)       1024      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 8, 8, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 8, 8, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              33558528  \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 48)                196656    \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 48)                0         \n",
            "=================================================================\n",
            "Total params: 57,590,256\n",
            "Trainable params: 57,585,392\n",
            "Non-trainable params: 4,864\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "221hhpBmFpJe",
        "colab_type": "code",
        "outputId": "b5edca11-fc3b-4bd9-fcf7-941c85f43640",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# number of epochs to train the NN\n",
        "epochs = 40\n",
        "\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "history = model.fit_generator(generator=train_generator,\n",
        "                                steps_per_epoch=train_generator.n//train_generator.batch_size,\n",
        "                                epochs=epochs,\n",
        "                                validation_data = test_generator,\n",
        "                                validation_steps = test_generator.n//test_generator.batch_size,\n",
        "                                callbacks=callbacks_list\n",
        "                                )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0717 08:41:23.966399 139942940280704 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "3598/3598 [==============================] - 287s 80ms/step - loss: 2.2175 - acc: 0.3831 - val_loss: 1.7068 - val_acc: 0.4963\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.49631, saving model to model_weights.h5\n",
            "Epoch 2/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.4772 - acc: 0.8565 - val_loss: 0.5545 - val_acc: 0.8488\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.49631 to 0.84881, saving model to model_weights.h5\n",
            "Epoch 3/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.2750 - acc: 0.9244 - val_loss: 0.1609 - val_acc: 0.9594\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.84881 to 0.95942, saving model to model_weights.h5\n",
            "Epoch 4/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.2177 - acc: 0.9430 - val_loss: 0.1332 - val_acc: 0.9667\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.95942 to 0.96666, saving model to model_weights.h5\n",
            "Epoch 5/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.1796 - acc: 0.9545 - val_loss: 0.1240 - val_acc: 0.9699\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.96666 to 0.96993, saving model to model_weights.h5\n",
            "Epoch 6/40\n",
            "3598/3598 [==============================] - 277s 77ms/step - loss: 0.1576 - acc: 0.9600 - val_loss: 0.1233 - val_acc: 0.9700\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.96993 to 0.97000, saving model to model_weights.h5\n",
            "Epoch 7/40\n",
            "3598/3598 [==============================] - 277s 77ms/step - loss: 0.1463 - acc: 0.9642 - val_loss: 0.1366 - val_acc: 0.9664\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.97000\n",
            "Epoch 8/40\n",
            "3598/3598 [==============================] - 277s 77ms/step - loss: 0.1377 - acc: 0.9665 - val_loss: 0.1226 - val_acc: 0.9722\n",
            "\n",
            "Epoch 00008: val_acc improved from 0.97000 to 0.97223, saving model to model_weights.h5\n",
            "Epoch 9/40\n",
            "3598/3598 [==============================] - 277s 77ms/step - loss: 0.1261 - acc: 0.9714 - val_loss: 0.1126 - val_acc: 0.9733\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.97223 to 0.97327, saving model to model_weights.h5\n",
            "Epoch 10/40\n",
            "3598/3598 [==============================] - 279s 77ms/step - loss: 0.1158 - acc: 0.9727 - val_loss: 0.1114 - val_acc: 0.9758\n",
            "\n",
            "Epoch 00010: val_acc improved from 0.97327 to 0.97578, saving model to model_weights.h5\n",
            "Epoch 11/40\n",
            "3598/3598 [==============================] - 279s 78ms/step - loss: 0.1132 - acc: 0.9738 - val_loss: 0.1069 - val_acc: 0.9752\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.97578\n",
            "Epoch 12/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.1037 - acc: 0.9760 - val_loss: 0.0989 - val_acc: 0.9778\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.97578 to 0.97779, saving model to model_weights.h5\n",
            "Epoch 13/40\n",
            "3598/3598 [==============================] - 277s 77ms/step - loss: 0.1002 - acc: 0.9767 - val_loss: 0.6485 - val_acc: 0.8167\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.97779\n",
            "Epoch 14/40\n",
            "3598/3598 [==============================] - 277s 77ms/step - loss: 0.0957 - acc: 0.9781 - val_loss: 0.0919 - val_acc: 0.9790\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.97779 to 0.97905, saving model to model_weights.h5\n",
            "Epoch 15/40\n",
            "3598/3598 [==============================] - 279s 77ms/step - loss: 0.0901 - acc: 0.9793 - val_loss: 0.0972 - val_acc: 0.9783\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.97905\n",
            "Epoch 16/40\n",
            "3598/3598 [==============================] - 279s 77ms/step - loss: 0.0849 - acc: 0.9807 - val_loss: 0.1064 - val_acc: 0.9750\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.97905\n",
            "Epoch 17/40\n",
            "3598/3598 [==============================] - 277s 77ms/step - loss: 0.0824 - acc: 0.9817 - val_loss: 0.1190 - val_acc: 0.9749\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.97905\n",
            "Epoch 18/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.0778 - acc: 0.9829 - val_loss: 0.0894 - val_acc: 0.9777\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.97905\n",
            "Epoch 19/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.0741 - acc: 0.9834 - val_loss: 0.0827 - val_acc: 0.9827\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.97905 to 0.98274, saving model to model_weights.h5\n",
            "Epoch 20/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.0704 - acc: 0.9839 - val_loss: 0.1036 - val_acc: 0.9816\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.98274\n",
            "Epoch 21/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.0714 - acc: 0.9842 - val_loss: 0.0889 - val_acc: 0.9813\n",
            "\n",
            "Epoch 00021: val_acc did not improve from 0.98274\n",
            "Epoch 22/40\n",
            "3598/3598 [==============================] - 279s 78ms/step - loss: 0.0684 - acc: 0.9851 - val_loss: 0.0972 - val_acc: 0.9825\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.98274\n",
            "Epoch 23/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.0645 - acc: 0.9857 - val_loss: 0.1114 - val_acc: 0.9811\n",
            "\n",
            "Epoch 00023: val_acc did not improve from 0.98274\n",
            "Epoch 24/40\n",
            "3598/3598 [==============================] - 279s 77ms/step - loss: 0.0657 - acc: 0.9858 - val_loss: 0.1034 - val_acc: 0.9820\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.98274\n",
            "Epoch 25/40\n",
            "3598/3598 [==============================] - 280s 78ms/step - loss: 0.0601 - acc: 0.9874 - val_loss: 0.1058 - val_acc: 0.9816\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.98274\n",
            "Epoch 26/40\n",
            "3598/3598 [==============================] - 279s 77ms/step - loss: 0.0633 - acc: 0.9862 - val_loss: 0.1314 - val_acc: 0.9725\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.98274\n",
            "Epoch 27/40\n",
            "3598/3598 [==============================] - 279s 78ms/step - loss: 0.0621 - acc: 0.9874 - val_loss: 0.1126 - val_acc: 0.9819\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.98274\n",
            "Epoch 28/40\n",
            "3598/3598 [==============================] - 280s 78ms/step - loss: 0.0590 - acc: 0.9881 - val_loss: 0.1119 - val_acc: 0.9816\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.98274\n",
            "Epoch 29/40\n",
            "3598/3598 [==============================] - 279s 77ms/step - loss: 0.0590 - acc: 0.9878 - val_loss: 0.1217 - val_acc: 0.9793\n",
            "\n",
            "Epoch 00029: val_acc did not improve from 0.98274\n",
            "Epoch 30/40\n",
            "3598/3598 [==============================] - 280s 78ms/step - loss: 0.0577 - acc: 0.9879 - val_loss: 0.1313 - val_acc: 0.9795\n",
            "\n",
            "Epoch 00030: val_acc did not improve from 0.98274\n",
            "Epoch 31/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.0570 - acc: 0.9883 - val_loss: 0.1096 - val_acc: 0.9832\n",
            "\n",
            "Epoch 00031: val_acc improved from 0.98274 to 0.98322, saving model to model_weights.h5\n",
            "Epoch 32/40\n",
            "3598/3598 [==============================] - 279s 78ms/step - loss: 0.0549 - acc: 0.9888 - val_loss: 0.1572 - val_acc: 0.9749\n",
            "\n",
            "Epoch 00032: val_acc did not improve from 0.98322\n",
            "Epoch 33/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.0554 - acc: 0.9894 - val_loss: 0.1218 - val_acc: 0.9820\n",
            "\n",
            "Epoch 00033: val_acc did not improve from 0.98322\n",
            "Epoch 34/40\n",
            "3598/3598 [==============================] - 280s 78ms/step - loss: 0.0557 - acc: 0.9889 - val_loss: 0.1116 - val_acc: 0.9820\n",
            "\n",
            "Epoch 00034: val_acc did not improve from 0.98322\n",
            "Epoch 35/40\n",
            "3598/3598 [==============================] - 280s 78ms/step - loss: 0.0533 - acc: 0.9894 - val_loss: 0.1305 - val_acc: 0.9782\n",
            "\n",
            "Epoch 00035: val_acc did not improve from 0.98322\n",
            "Epoch 36/40\n",
            "3598/3598 [==============================] - 279s 78ms/step - loss: 0.0532 - acc: 0.9897 - val_loss: 0.1027 - val_acc: 0.9841\n",
            "\n",
            "Epoch 00036: val_acc improved from 0.98322 to 0.98413, saving model to model_weights.h5\n",
            "Epoch 37/40\n",
            "3598/3598 [==============================] - 279s 77ms/step - loss: 0.0552 - acc: 0.9891 - val_loss: 0.1186 - val_acc: 0.9788\n",
            "\n",
            "Epoch 00037: val_acc did not improve from 0.98413\n",
            "Epoch 38/40\n",
            "3598/3598 [==============================] - 278s 77ms/step - loss: 0.0537 - acc: 0.9896 - val_loss: 0.1681 - val_acc: 0.9765\n",
            "\n",
            "Epoch 00038: val_acc did not improve from 0.98413\n",
            "Epoch 39/40\n",
            "3598/3598 [==============================] - 279s 77ms/step - loss: 0.0547 - acc: 0.9893 - val_loss: 0.1237 - val_acc: 0.9830\n",
            "\n",
            "Epoch 00039: val_acc did not improve from 0.98413\n",
            "Epoch 40/40\n",
            "3598/3598 [==============================] - 279s 78ms/step - loss: 0.0538 - acc: 0.9896 - val_loss: 0.1323 - val_acc: 0.9811\n",
            "\n",
            "Epoch 00040: val_acc did not improve from 0.98413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM3FXze_F-HR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SAVE MODEL\n",
        "model_json = model.to_json()\n",
        "with open(\"katakana_model_keras.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"katakana_model_keras.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O560DyG1yujK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle_out = open(\"kata_class_indices.pickle\",\"wb\")\n",
        "pickle.dump(test_generator.class_indices, pickle_out)\n",
        "pickle_out.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StslGTwry2fA",
        "colab_type": "code",
        "outputId": "25818835-619e-46ea-9afe-b75840a8228a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_generator.class_indices == train_generator.class_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbAdMUsKzL6J",
        "colab_type": "code",
        "outputId": "894a7470-a145-4301-f559-c7cfb3695bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "test_generator.class_indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'166': 0,\n",
              " '168': 1,\n",
              " '170': 2,\n",
              " '177': 3,\n",
              " '178': 4,\n",
              " '179': 5,\n",
              " '180': 6,\n",
              " '181': 7,\n",
              " '182': 8,\n",
              " '183': 9,\n",
              " '184': 10,\n",
              " '185': 11,\n",
              " '186': 12,\n",
              " '187': 13,\n",
              " '188': 14,\n",
              " '189': 15,\n",
              " '190': 16,\n",
              " '191': 17,\n",
              " '192': 18,\n",
              " '193': 19,\n",
              " '194': 20,\n",
              " '195': 21,\n",
              " '196': 22,\n",
              " '197': 23,\n",
              " '198': 24,\n",
              " '199': 25,\n",
              " '200': 26,\n",
              " '201': 27,\n",
              " '202': 28,\n",
              " '203': 29,\n",
              " '204': 30,\n",
              " '205': 31,\n",
              " '206': 32,\n",
              " '207': 33,\n",
              " '208': 34,\n",
              " '209': 35,\n",
              " '210': 36,\n",
              " '211': 37,\n",
              " '212': 38,\n",
              " '213': 39,\n",
              " '214': 40,\n",
              " '215': 41,\n",
              " '216': 42,\n",
              " '217': 43,\n",
              " '218': 44,\n",
              " '219': 45,\n",
              " '220': 46,\n",
              " '221': 47}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nc8JQjHgNwEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}